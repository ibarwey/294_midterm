{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Logic Definition of Generalization"
      ],
      "metadata": {
        "id": "9TLwAyuBBme1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (a)"
      ],
      "metadata": {
        "id": "9SWxeepTBvOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to show empirically that n_full/n_avg appraoches 2 for dimensions 2, 4, and 16, I start by creating a random dataset with X being randomly generated by random.rand, and the y labels generated by random.randint with values of 0 or 1 for binary classification. I then, for dimensions of 2, 4, and 8, remove a data point from the dataset and run the knn classifier on the data. In order to determine whether the data point is needed memory, i predict that point on the classifier, and check whether the prediction was correct. If it was, this point was not necessary for fitting the algorithm. We run this 100 times on each dimension and average the count of important points to get n_avg. The output was as follows:\n",
        "\n",
        "> d=2: n_full=4, Avg. req. points for memorization n_avg=2.22, n_full/n_avg=1.80\n",
        "\n",
        "> d=4: n_full=16, Avg. req. points for memorization n_avg=8.06, n_full/n_avg=1.99\n",
        "\n",
        "> d=8: n_full=256, Avg. req. points for memorization n_avg=127.56, n_full/n_avg=2.01\n",
        "\n",
        "We can see that the values converge to around 2.00."
      ],
      "metadata": {
        "id": "ZrIgJQBNB30M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWVT2rpSBiAl"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def generate_random_dataset(dimension, num_points):\n",
        "    random.seed(1628)\n",
        "    X = np.random.rand(num_points, dimension)\n",
        "    y = np.random.randint(2, size=num_points)\n",
        "    return X, y\n",
        "\n",
        "def find_important_rows_count(X, y, num_points):\n",
        "    non_important_rows_count = 0\n",
        "    knn = KNeighborsClassifier(n_neighbors=1)\n",
        "    knn.fit(X, y)\n",
        "    for i in range(num_points):\n",
        "        X_this = np.delete(X, i, axis=0)\n",
        "        y_this = np.delete(y, i, axis=0)\n",
        "        knn.fit(X_this, y_this)\n",
        "        prediction = knn.predict(X[i].reshape(1, -1))\n",
        "        if prediction[0] == y[i]:\n",
        "            non_important_rows_count += 1\n",
        "    return num_points - non_important_rows_count\n",
        "\n",
        "dimensions = [2, 4, 8]\n",
        "\n",
        "for dim in dimensions:\n",
        "    num_points = 2**dim\n",
        "    total = 0\n",
        "    for _ in range(100):\n",
        "      X, y = generate_random_dataset(dim, num_points)\n",
        "      count = find_important_rows_count(X, y, num_points)\n",
        "      total += count\n",
        "    n_avg = total / 100\n",
        "\n",
        "    print(f\"d={dim}: n_full={num_points}, Avg. req. points for memorization n_avg={n_avg:.2f}, n_full/n_avg={num_points/n_avg:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (b)"
      ],
      "metadata": {
        "id": "i9L3UG_TD3yM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I ran my experiment with a 4-class classification problem by generating labels in the range 0 to 3 instead of 0 to 1. The expected results were values approaching c/c-1, in this case 1.33. My outputs did in fact approach 1.33.\n",
        "\n",
        "> d=2: n_full=4, Avg. req. points for memorization n_avg=2.99, n_full/n_avg=1.34\n",
        "\n",
        "> d=4: n_full=16, Avg. req. points for memorization n_avg=12.11, n_full/n_avg=1.32\n",
        "\n",
        "> d=8: n_full=256, Avg. req. points for memorization n_avg=191.96, n_full/n_avg=1.33"
      ],
      "metadata": {
        "id": "JXAutyqUD6ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "\n",
        "def generate_random_dataset(dimension, num_points):\n",
        "    X = np.random.rand(num_points, dimension)\n",
        "    y = np.random.randint(4, size=num_points)\n",
        "    return X, y\n",
        "\n",
        "def find_important_rows_count(X, y, num_points):\n",
        "    non_important_rows_count = 0\n",
        "    knn = KNeighborsClassifier(n_neighbors=1)\n",
        "    knn.fit(X, y)\n",
        "    for i in range(num_points):\n",
        "        X_this = np.delete(X, i, axis=0)\n",
        "        y_this = np.delete(y, i, axis=0)\n",
        "        knn.fit(X_this, y_this)\n",
        "        prediction = knn.predict(X[i].reshape(1, -1))\n",
        "        if prediction[0] == y[i]:\n",
        "            non_important_rows_count += 1\n",
        "    return num_points - non_important_rows_count\n",
        "\n",
        "dimensions = [2, 4, 8]\n",
        "\n",
        "for dim in dimensions:\n",
        "    num_points = 2**dim\n",
        "    total = 0\n",
        "    for _ in range(100):\n",
        "      X, y = generate_random_dataset(dim, num_points)\n",
        "      count = find_important_rows_count(X, y, num_points)\n",
        "      total += count\n",
        "    n_avg = total / 100\n",
        "\n",
        "    print(f\"d={dim}: n_full={num_points}, Avg. req. points for memorization n_avg={n_avg:.2f}, n_full/n_avg={num_points/n_avg:.2f}\")"
      ],
      "metadata": {
        "id": "svgjQV0KEqag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Finite State Machine Generalization:"
      ],
      "metadata": {
        "id": "1VTuA4DfFHLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (a)"
      ],
      "metadata": {
        "id": "IbUWzNyhFHzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use the sklearn breast cancer dataset as a binary dataset to run our DT on. I first run the DT and print a tree with export_text, then count the number of if-thens by checking the times when the tree makes a conditional decision or branch. I also note accuracy.\n",
        "\n",
        "Output:\n",
        "\n",
        "> if-then count: 30\n",
        "\n",
        "> original accuracy:  0.9385964912280702"
      ],
      "metadata": {
        "id": "AhEl7qDrFeBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_text\n",
        "\n",
        "# load data\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#fit\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# get feature names as list\n",
        "feature_names = list(data.feature_names)\n",
        "\n",
        "# get if-then rules\n",
        "tree_rules = export_text(clf, feature_names=feature_names)\n",
        "num_clauses = tree_rules.count(\"<=\") + tree_rules.count(\">\")\n",
        "\n",
        "# printing for experiments\n",
        "accuracy_og = clf.score(X_test, y_test)\n",
        "print(f\"if-then count: {num_clauses}\")\n",
        "print(\"original accuracy: \", accuracy_og)"
      ],
      "metadata": {
        "id": "drgNmEG6Fajj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strategy 1. max_depth**\n",
        "\n",
        "My first method of reducing if-then clauses was reducing the max_depth of the tree. in order to do this while still maintaining a decent accuracy, I started from 1 and looped up to the depth of the original tree while checking if the proposed depth provides a decent accuracy. For the same run as above, my output was:\n",
        "\n",
        "> best depth:  1\n",
        "\n",
        "> if-then count:  2\n",
        "\n",
        "> accuracy:  0.8947368421052632\n",
        "\n",
        "> original accuracy:  0.9385964912280702"
      ],
      "metadata": {
        "id": "CPon_6VuGCsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Strategy 1. max_depth ##\n",
        "\n",
        "og_depth = clf.tree_.max_depth\n",
        "\n",
        "for i in range(1,og_depth+1):\n",
        "  clf1 = DecisionTreeClassifier(random_state=42, max_depth=i)\n",
        "  clf1.fit(X_train, y_train)\n",
        "  accuracy1 = clf1.score(X_test, y_test)\n",
        "  if accuracy1 >= accuracy_og-0.2:\n",
        "    best_depth = i\n",
        "    break\n",
        "\n",
        "print(\"best depth: \", best_depth)\n",
        "tree_rules_1 = export_text(clf1, feature_names=feature_names)\n",
        "num_clauses_1 = tree_rules_1.count(\"<=\") + tree_rules_1.count(\">\")\n",
        "print(\"if-then count: \", num_clauses_1)\n",
        "print(\"accuracy: \", accuracy1)\n",
        "print(\"original accuracy: \", accuracy_og)"
      ],
      "metadata": {
        "id": "5XQ73EzrGDKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strategy 2. max_leaf_nodes**\n",
        "\n",
        "My next method of reducing if-then clauses was reducing the max_leaf_nodes of the tree. This method was very similar to the depth method, just adjusting for max_leaf_nodes instead. For the same run as above, my output was:\n",
        "\n",
        "> best leaves:  2\n",
        "\n",
        "> if-then count:  2\n",
        "\n",
        "> accuracy:  0.8947368421052632\n",
        "\n",
        "> original accuracy:  0.9385964912280702"
      ],
      "metadata": {
        "id": "BIiO0qc_HNz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Strategy 2. leaf nodes ##\n",
        "\n",
        "og_num_leaf_nodes = clf.tree_.n_leaves\n",
        "\n",
        "for i in range(2, og_num_leaf_nodes+1):\n",
        "  clf2 = DecisionTreeClassifier(random_state=42, max_leaf_nodes=i)\n",
        "  clf2.fit(X_train, y_train)\n",
        "  accuracy2 = clf2.score(X_test, y_test)\n",
        "  if accuracy2 >= accuracy_og-0.2:\n",
        "    best_leaves = i\n",
        "    break\n",
        "\n",
        "print(\"best leaves: \", best_leaves)\n",
        "tree_rules_2 = export_text(clf2, feature_names=feature_names)\n",
        "num_clauses_2 = tree_rules_2.count(\"<=\") + tree_rules_2.count(\">\")\n",
        "print(\"if-then count: \", num_clauses_2)\n",
        "print(\"accuracy: \", accuracy2)\n",
        "print(\"original accuracy: \", accuracy_og)"
      ],
      "metadata": {
        "id": "qFpvcjtAHjRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strategy 3. Combination**\n",
        "\n",
        "Finally, I wanted to try optimizing both the tree depth and leaf node count at the same time. I did this with a nested for-loop as seen below. As a result, I was able to reduce the if-then clauses count to only 2 while maintaining a ~90% accuracy. Notably, combining both methods was equally as effective as either method alone for the same accuracy, as all 3 reduced if-then clauses to 2.\n",
        "\n",
        "Output:\n",
        "> final if-then statements count:  2\n",
        "\n",
        "> final depth:  1\n",
        "\n",
        "> final leaves:  2\n",
        "\n",
        "> final accuracy:  0.8947368421052632\n",
        "\n",
        "> final tree:\n",
        "\n",
        "|--- mean concave points <= 0.05\n",
        "\n",
        "|   |--- class: 1\n",
        "\n",
        "|--- mean concave points >  0.05\n",
        "\n",
        "|   |--- class: 0"
      ],
      "metadata": {
        "id": "Cpkvav01Hk8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Final: combining both metrics ##\n",
        "\n",
        "for d in range(1,og_depth+1):\n",
        "  for l in range(2, og_num_leaf_nodes+1):\n",
        "    clf_final = DecisionTreeClassifier(random_state=42, max_depth=d, max_leaf_nodes=l)\n",
        "    clf_final.fit(X_train, y_train)\n",
        "    accuracy_final = clf_final.score(X_test, y_test)\n",
        "    if accuracy_final >= accuracy_og-0.2:\n",
        "      final_depth, final_leaves = d, l\n",
        "      break\n",
        "\n",
        "# clf_final = DecisionTreeClassifier(random_state=42, max_leaf_nodes=best_leaves, max_depth=best_depth)\n",
        "# clf_final.fit(X_train, y_train)\n",
        "\n",
        "tree_rules_final = export_text(clf_final, feature_names=feature_names)\n",
        "num_clauses_final = tree_rules_final.count(\"<=\") + tree_rules_final.count(\">\")\n",
        "\n",
        "print(\"final if-then statements count: \", num_clauses_final)\n",
        "print(\"final depth: \", clf_final.tree_.max_depth)\n",
        "print(\"final leaves: \", clf_final.tree_.n_leaves)\n",
        "print(\"final accuracy: \", clf_final.score(X_test, y_test))\n",
        "print()\n",
        "print(\"final tree: \")\n",
        "print(tree_rules_final)"
      ],
      "metadata": {
        "id": "TQU7HV0LINRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (b)"
      ],
      "metadata": {
        "id": "JlLlvQVMIj7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I attempt the same method as in (a) on a different sklearn dataset, which is a 10-class classification for digits. This dataset has a much larger initial if-then clause count and lower initial accuracy.\n",
        "\n",
        "Output:\n",
        "> if-then count: 40\n",
        "\n",
        "> original accuracy:  0.8771929824561403"
      ],
      "metadata": {
        "id": "6vB4X7FqIlJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_text\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# load data\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#fit\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# get feature names as list\n",
        "feature_names = list(data.feature_names)\n",
        "\n",
        "# get if-then rules\n",
        "tree_rules = export_text(clf, feature_names=feature_names)\n",
        "num_clauses = tree_rules.count(\"<=\") + tree_rules.count(\">\")\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy_og = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# printing for experiments\n",
        "#accuracy_og = clf.score(X_test, y_test)\n",
        "print(f\"if-then count: {num_clauses}\")\n",
        "print(\"original accuracy: \", accuracy_og)"
      ],
      "metadata": {
        "id": "bEmb2PJ6Ils4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If-then reduction method: Combined**\n",
        "\n",
        "Because the method of combining depth analysis and leaf node analysis resulted in the same number of if-then clauses as the separate methods and with similar accuracy, I opted to simply run the combined script. The results were very similar to my original dataset, but with a slightly lower accuracy of 88.5%.\n",
        "\n",
        "> final if-then statements count:  2\n",
        "\n",
        "> final depth:  1\n",
        "\n",
        "> final leaves:  2\n",
        "\n",
        "> final accuracy:  0.8859649122807017\n",
        "\n",
        "> final tree:\n",
        "\n",
        "|--- worst perimeter <= 113.75\n",
        "\n",
        "|   |--- class: 1\n",
        "\n",
        "|--- worst perimeter >  113.75\n",
        "\n",
        "|   |--- class: 0\n"
      ],
      "metadata": {
        "id": "HBlIk_KdK3qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Final: finding best depth and num. leaf nodes ##\n",
        "og_depth = clf.tree_.max_depth\n",
        "og_num_leaf_nodes = clf.tree_.n_leaves\n",
        "\n",
        "for d in range(1,og_depth+1):\n",
        "  for l in range(2, og_num_leaf_nodes+1):\n",
        "    clf_final = DecisionTreeClassifier(random_state=45, max_depth=d, max_leaf_nodes=l)\n",
        "    clf_final.fit(X_train, y_train)\n",
        "    accuracy_final = clf_final.score(X_test, y_test)\n",
        "    if accuracy_final >= accuracy_og-0.2:\n",
        "      final_depth, final_leaves = d, l\n",
        "      break\n",
        "\n",
        "tree_rules_final = export_text(clf_final, feature_names=feature_names)\n",
        "num_clauses_final = tree_rules_final.count(\"<=\") + tree_rules_final.count(\">\")\n",
        "\n",
        "print(\"final if-then statements count: \", num_clauses_final)\n",
        "print(\"final depth: \", clf_final.tree_.max_depth)\n",
        "print(\"final leaves: \", clf_final.tree_.n_leaves)\n",
        "print(\"final accuracy: \", accuracy_final)\n",
        "print()\n",
        "print(\"final tree: \")\n",
        "print(tree_rules_final)"
      ],
      "metadata": {
        "id": "uHk8fLnkKssn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (c)"
      ],
      "metadata": {
        "id": "1Pn_hhWYLaVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate the random dataset for use in this section, I used the same method as in 6.1 with binary classification. Due to the nature of random datasets, the accuracy was lower than the other attempts, as well as the number of if-then clauses.\n",
        "\n",
        "> if-then count: 64\n",
        "> original accuracy:  0.65"
      ],
      "metadata": {
        "id": "nWK1cXi_LbTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import export_text\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def generate_random_dataset(dimension, num_points):\n",
        "    X = np.random.rand(num_points, dimension)\n",
        "    y = np.random.randint(2, size=num_points)\n",
        "    return X, y\n",
        "\n",
        "X, y = generate_random_dataset(2, 100)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "clfrand = DecisionTreeClassifier()\n",
        "clfrand.fit(X_train, y_train)\n",
        "\n",
        "tree_rules = export_text(clfrand)\n",
        "num_clauses = tree_rules.count(\"<=\") + tree_rules.count(\">\")\n",
        "\n",
        "y_pred = clfrand.predict(X_test)\n",
        "accuracy_og = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"if-then count: {num_clauses}\")\n",
        "print(\"original accuracy: \", accuracy_og)"
      ],
      "metadata": {
        "id": "nvmAgaAnLbkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the accuracy is much more volatile for random datasets, I opted to only select a depth-leaf-node combination if it equaled or exceeded our original accuracy for this run. This lead to a final if-then count of 2 and an increase in accuracy to 0.7.\n",
        "\n",
        "> final if-then statements count:  2\n",
        "\n",
        "> final depth:  1\n",
        "\n",
        "> final leaves:  2\n",
        "\n",
        "> final accuracy:  0.7\n",
        "\n",
        "> final tree:\n",
        "\n",
        "|--- feature_0 <= 0.89\n",
        "\n",
        "|   |--- class: 1\n",
        "\n",
        "|--- feature_0 >  0.89\n",
        "\n",
        "|   |--- class: 0"
      ],
      "metadata": {
        "id": "2blK24IlL7Sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Final: finding best depth and num. leaf nodes ##\n",
        "og_depth = clfrand.tree_.max_depth\n",
        "og_num_leaf_nodes = clfrand.tree_.n_leaves\n",
        "\n",
        "for d in range(1,og_depth+1):\n",
        "  for l in range(2, og_num_leaf_nodes+1):\n",
        "    clf_final = DecisionTreeClassifier(random_state=45, max_depth=d, max_leaf_nodes=l)\n",
        "    clf_final.fit(X_train, y_train)\n",
        "    y_pred = clf_final.predict(X_test)\n",
        "    accuracy_final = accuracy_score(y_test, y_pred)\n",
        "    if accuracy_final >= accuracy_og:\n",
        "      final_depth, final_leaves = d, l\n",
        "      break\n",
        "\n",
        "tree_rules_final = export_text(clf_final)\n",
        "num_clauses_final = tree_rules_final.count(\"<=\") + tree_rules_final.count(\">\")\n",
        "\n",
        "print(\"final if-then statements count: \", num_clauses_final)\n",
        "print(\"final depth: \", clf_final.tree_.max_depth)\n",
        "print(\"final leaves: \", clf_final.tree_.n_leaves)\n",
        "print(\"final accuracy: \", accuracy_final)\n",
        "print()\n",
        "print(\"final tree: \")\n",
        "print(tree_rules_final)"
      ],
      "metadata": {
        "id": "P-l_gPncL636"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Compression"
      ],
      "metadata": {
        "id": "FWTVj7VUNI-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (a)"
      ],
      "metadata": {
        "id": "sBBlCY3WOKKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the zlib.compress function to compress a randomly generated string of size 200, arbitrarily selected. The results were as follows:\n",
        "\n",
        "> Original string length: 200\n",
        "\n",
        "> Compressed string length: 199\n",
        "\n",
        "> Compression ratio: .995"
      ],
      "metadata": {
        "id": "GvZeSALlNK_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "import zlib\n",
        "\n",
        "#generate random string\n",
        "chars = string.ascii_letters + string.digits + string.punctuation\n",
        "strand = ''.join(random.choice(chars) for _ in range(200))\n",
        "\n",
        "print(strand)\n",
        "\n",
        "#apply compression\n",
        "encoded = strand.encode()\n",
        "compressed = zlib.compress(strand.encode())\n",
        "\n",
        "#calculate ratio\n",
        "ratio = len(compressed) / len(strand)\n",
        "\n",
        "#print results\n",
        "print(\"Original string length:\", len(strand))\n",
        "print(\"Compressed string length:\", len(compressed))\n",
        "print(\"Compression ratio:\", ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfpt8MQuNM8D",
        "outputId": "3e5a6aaa-0474-4ec7-a00f-200f52d77241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N>kt|6e;k)AM2~@B)9IrJ.;;NG#0gzIHf~EgBTh?\\E9IxI3e$,O-}c1*KjO*.opPc+X:rLv{AKeAQhC?1,*F*~CZ!Fn5Ma$n556jGYd-]gHze`jXG@hagN15|Li&;S+kFd9bd(P93hHXZ7ptV72!`OqZli~a.jb\\@4H!O!`dQlb\"A@U5_CV149fXn{p9OoU^$H]%Ek<\"\n",
            "Original string length: 200\n",
            "Compressed string length: 199\n",
            "Compression ratio: 0.995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (b)"
      ],
      "metadata": {
        "id": "KsE1QdmBOLqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected compression ratio in (a) is approximately 1. This is because when viewed through its relationship to generalization, we expect that when G is close to 1, this indicates no compression and the model hasn't reduced complexity. This is expected for a randomly generated string, as it is highly generalized so there is minimal compression."
      ],
      "metadata": {
        "id": "7oLKoSPYOIIQ"
      }
    }
  ]
}